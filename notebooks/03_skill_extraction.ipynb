{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb01f666",
   "metadata": {},
   "source": [
    "## Step 1 : Load Cleaned Data\n",
    "Load the preprocessed data from `data/processed/cleaned_job_descriptions.csv`.<br>\n",
    "The `pd.read_csv()` function reads the CSV file into pandas DataFrame.<br>\n",
    "The data is already cleaned with skill pattern protection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c04d630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total job listings: 2277\n",
      "Coloumns: ['Unnamed: 0', 'Job Title', 'Job Description']\n",
      "\n",
      "Job 1: Flutter Developer\n",
      "Description: we are looking for hire experts flutter developer so you are eligible this post then apply your resu\n",
      "\n",
      "Job 2: Django Developer\n",
      "Description: pythondjango developerlead job codepdj  strong python experience in api development restrpc experien\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned job listings data\n",
    "df = pd.read_csv('../data/processed/job_title_des_cleaned.csv')\n",
    "\n",
    "print(f\"Total job listings: {len(df)}\")\n",
    "print(f\"Coloumns: {df.columns.tolist()}\")\n",
    "\n",
    "for i in range(2):\n",
    "    print(f\"\\nJob {i+1}: {df['Job Title'].iloc[i]}\")\n",
    "    print(f\"Description: {df['Job Description'].iloc[i][:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16752ca",
   "metadata": {},
   "source": [
    "## Stap 2: Test Skill Persevation\n",
    "Verify that skills with special characters are preserved correctly.<br>\n",
    "Check if C#, C++, .NET, and other skills are intact in the cleaned data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8f2be124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c#: Found in 99 job descriptions\n",
      "c++: Found in 2277 job descriptions\n",
      "F#: Found in 1 job descriptions\n",
      ".net: Found in 775 job descriptions\n",
      "node.js: Found in 340 job descriptions\n",
      "asp.net: Found in 48 job descriptions\n"
     ]
    }
   ],
   "source": [
    "skill_patterns = ['c#', 'c++', 'F#','.net', 'node.js', 'asp.net']\n",
    "for skill in skill_patterns:\n",
    "    count = df['Job Description'].str.lower().str.contains(skill, case=False, na=False).sum()\n",
    "    print(f\"{skill}: Found in {count} job descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e0a7f",
   "metadata": {},
   "source": [
    "## Step 3: Initialize TF-IDF Vectorizer with Custom Tokenizer\n",
    "\n",
    "The `TfidfVectorizer` converts text documents to TF-IDF feature vectors.<br>\n",
    "`max_features` keeps only the top N most important words.<br>\n",
    "`min_df` ignores words that appear in too few documents.<br>\n",
    "`max_df` ignores words that appear in too many documents.<br>\n",
    "`stop_words` removes common English words like \"the\", \"is\", \"and\".<br>\n",
    "The `tokenizer` function preserves special characters like #, +, and . for skill names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b129cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Custom tokenizer that preserves special characters for skills\n",
    "def skill_aware_tokenizer(text):\n",
    "    \"\"\"\n",
    "    Tokenize text while preserving special characters (#, +, .) for skill names.\n",
    "    Splits on spaces but keeps skill patterns like 'c#', 'c++', '.net' intact.\n",
    "    \"\"\"\n",
    "    # Split on whitespace\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Initialize TF-IDF Vectorizer with custom tokenizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=skill_aware_tokenizer,  # Use custom tokenizer to preserve special chars\n",
    "    max_features=1000,                # Limit to top 1000 features\n",
    "    min_df=2,                         # Word must appear in at least 2 documents\n",
    "    max_df=0.8,                       # Word must not appear in more than 80% of documents\n",
    "    stop_words='english',             # Remove common English stop words\n",
    "    token_pattern=None                # Disable default token pattern to use custom tokenizer\n",
    ")    \n",
    "\n",
    "# Fit and transform cleaned job descriptions\n",
    "tfidf_matrix = tfidf.fit_transform(df['Job Description'])\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Number of job descriptions: {tfidf_matrix.shape[0]}\")\n",
    "print(f\"Features (words): {tfidf_matrix.shape[1]}\")"
   ]
  },
  {"cell_type": "markdown", "id": "0408b311", "metadata": {}, "source": ["## Step 4 : View Vocabulary\n", "The `get_feature_names_out()` method returns the vocabulary (list of words).<br>\n", "Check if skills with special characters are present in the vocabulary.<br>\n", "With custom tokenizer, skills like 'c#', 'c++', '.net' should now be preserved."]},
  {"cell_type": "code", "execution_count": null, "id": "ba06c0f4", "metadata": {}, "outputs": [], "source": ["feature_names = tfidf.get_feature_names_out()  # Display first 20 feature names\n", "print(\"Sample feature names:\", feature_names[:20])\n", "print(f\"=\"*80)\n", "# Check for preserved skills (now checking for actual skill names in data)\n", "print(\"Checking for preserved skills in vocabulary:\")\n", "skills_to_check = ['c#', 'c++', 'net', 'node.js', 'asp.net', 'python', 'django', 'react', '.net']\n", "for skill in skills_to_check:\n", "    if skill in feature_names:\n", "        # Find index of skill\n", "        idx = list(feature_names).index(skill)\n", "        print(f\"✓ '{skill}': Found (index {idx})\")\n", "    else:\n", "        print(f\"✗ '{skill}': Not found\")\n", "print(f\"=\"*80)\n", "# Search for skills with special chars in vocabulary\n", "print(\"\\nSearching for features containing special characters:\")\n", "special_char_features = [f for f in feature_names if any(char in f for char in ['#', '+', '.'])]\n", "if special_char_features:\n", "    print(f\"Found {len(special_char_features)} features with special characters:\")\n", "    for feature in special_char_features[:20]:  # Show first 20\n", "        print(f\"  - {feature}\")\n", "else:\n", "    print(\"No features with special characters found.\")\n", "print(f\"=\"*80)\n", "# View first 20 words\n", "print(\"\\nFirst 20 words in vocabulary:\")\n", "print(feature_names[:20])\n"]},
  {
   "cell_type": "markdown",
   "id": "c2598754",
   "metadata": {},
   "source": [
    "## Step 5: Extract Skills from a Document\n",
    "\n",
    "Extract the top words (potential skills) from a single document.<br>\n",
    "TF-IDF scores indicate how important each word is for that document.<br>\n",
    "Filter words against a predefined skill list to get actual skills.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e25d1d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job 1: Flutter Developer\n",
      "Skills extracted:\n",
      "  - flutter: 0.2140\n",
      "================================================================================\n",
      "\n",
      "Job 2: Django Developer\n",
      "Skills extracted:\n",
      "  - api: 0.3392\n",
      "  - json: 0.1975\n",
      "  - linux: 0.1814\n",
      "  - sql: 0.1538\n",
      "  - python: 0.1426\n",
      "================================================================================\n",
      "\n",
      "Job 3: Machine Learning\n",
      "Skills extracted:\n",
      "  - python: 0.1075\n",
      "  - java: 0.0545\n",
      "================================================================================\n",
      "\n",
      "Job 4: iOS Developer\n",
      "Skills extracted:\n",
      "  - ios: 0.4664\n",
      "================================================================================\n",
      "\n",
      "Job 5: Full Stack Developer\n",
      "Skills extracted:\n",
      "  - react: 0.2398\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define skill list (lowercase)\n",
    "skill_list = [\n",
    "    # Programming languages\n",
    "    'python', 'java', 'javascript', 'c#', 'c++', 'csharp', 'cplusplus',\n",
    "    'ruby', 'php', 'swift', 'kotlin', 'go', 'rust', 'r', 'typescript',\n",
    "\n",
    "    # Frameworks\n",
    "    'django', 'flask', 'react', 'angular', 'vue', 'spring', 'express',\n",
    "    'nodejs', 'aspnet', 'aspnetcore', 'aspnetmvc',\n",
    "\n",
    "    # Data science / ML\n",
    "    'tensorflow', 'pytorch', 'keras', 'scikit', 'pandas', 'numpy',\n",
    "    'spark', 'hadoop', 'sklearn',\n",
    "\n",
    "    # Databases\n",
    "    'sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'sqlite',\n",
    "\n",
    "    # Tools / Platforms\n",
    "    'docker', 'kubernetes', 'aws', 'azure', 'gcp', 'git', 'jenkins',\n",
    "    'linux', 'ubuntu', 'windows',\n",
    "\n",
    "    # Mobile\n",
    "    'android', 'ios', 'flutter', 'reactnative',\n",
    "\n",
    "    # Microsoft technologies\n",
    "    'net', 'dotnet', 'dotnetcore', 'dotnetframework',\n",
    "\n",
    "    # Web\n",
    "    'html', 'css', 'json', 'xml', 'rest', 'graphql', 'api'\n",
    "]\n",
    "\n",
    "# Function to extract skills from a document\n",
    "def extract_skills(doc_index, tfidf_matrix, feature_names, skill_list, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Extract skills with TF-IDF score above threshold.\n",
    "\n",
    "    Args:\n",
    "        doc_index: Index of the document\n",
    "        tfidf_matrix: TF-IDF matrix\n",
    "        feature_names: List of vocabulary words\n",
    "        skill_list: List of known skills\n",
    "        threshold: Minimum TF-IDF score to consider\n",
    "\n",
    "    Returns:\n",
    "        List of (skill, score) tuples\n",
    "    \"\"\"\n",
    "    # Get TF-IDF scores for this document\n",
    "    doc_tfidf = tfidf_matrix[doc_index].toarray()[0]\n",
    "\n",
    "    # Create dictionary: word (feature_name) -> score for this document\n",
    "    word_scores = dict(zip(feature_names, doc_tfidf))\n",
    "\n",
    "    # Filter for skills above threshold\n",
    "    skills = [(word, score) for word, score in word_scores.items()\n",
    "                if  word in skill_list and score > threshold]\n",
    "\n",
    "    # Sort by score (highest first)\n",
    "    skills.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return skills\n",
    "\n",
    "# Extract skills for first 5 documents\n",
    "for i in range(5):\n",
    "    skills = extract_skills(i, tfidf_matrix, feature_names, skill_list)\n",
    "    print(f\"\\nJob {i+1}: {df['Job Title'].iloc[i]}\")\n",
    "    print(\"Skills extracted:\")\n",
    "    for skill, score in skills:\n",
    "        print(f\"  - {skill}: {score:.4f}\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807c637",
   "metadata": {},
   "source": [
    "## Step 6: Extract Skills for All Documents\n",
    "\n",
    "Apply skill extraction to all documents in the dataset.<br>\n",
    "The `apply()` method processes each document.<br>\n",
    "Save extracted skills as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aed8788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills extracted for all jobs:\n",
      "Total jobs: 2277\n",
      "\n",
      "Sample results:\n",
      "Job 1 (Flutter Developer): ['flutter']\n",
      "Job 2 (Django Developer): ['api', 'json', 'linux', 'sql', 'python']\n",
      "Job 3 (Machine Learning): ['python', 'java']\n",
      "Job 4 (iOS Developer): ['ios']\n",
      "Job 5 (Full Stack Developer): ['react']\n"
     ]
    }
   ],
   "source": [
    "# Function to extract only skill names from a document\n",
    "def extract_skills_list(doc_index):\n",
    "    skills_with_scores= extract_skills(doc_index, tfidf_matrix, feature_names, skill_list)\n",
    "    return [skill for skill, score in skills_with_scores]\n",
    "\n",
    "# Apply to all documents\n",
    "df['extracted_skills'] = [extract_skills_list(i) for i in range(len(df))]\n",
    "\n",
    "# Display results\n",
    "print(\"Skills extracted for all jobs:\")\n",
    "print(f\"Total jobs: {len(df)}\")\n",
    "print(\"\\nSample results:\")\n",
    "for i in range(5):\n",
    "    skills = df['extracted_skills'].iloc[i]\n",
    "    print(f\"Job {i+1} ({df['Job Title'].iloc[i]}): {skills}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c26767",
   "metadata": {},
   "source": [
    "## Step 7: Analyze Extracted Skills\n",
    "\n",
    "Analyze the distribution of skills across all job descriptions.<br>\n",
    "Count how many jobs require each skill.<br>\n",
    "Identify the most in-demand skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "53309f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most common skills:\n",
      "javascript: 569 jobs (25.0%)\n",
      "html: 463 jobs (20.3%)\n",
      "css: 458 jobs (20.1%)\n",
      "java: 356 jobs (15.6%)\n",
      "python: 344 jobs (15.1%)\n",
      "git: 343 jobs (15.1%)\n",
      "php: 338 jobs (14.8%)\n",
      "mysql: 325 jobs (14.3%)\n",
      "aws: 309 jobs (13.6%)\n",
      "sql: 299 jobs (13.1%)\n",
      "rest: 279 jobs (12.3%)\n",
      "api: 269 jobs (11.8%)\n",
      "ios: 256 jobs (11.2%)\n",
      "angular: 234 jobs (10.3%)\n",
      "linux: 215 jobs (9.4%)\n",
      "react: 206 jobs (9.0%)\n",
      "json: 175 jobs (7.7%)\n",
      "docker: 161 jobs (7.1%)\n",
      "android: 160 jobs (7.0%)\n",
      "mongodb: 157 jobs (6.9%)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten list of all extracted skills\n",
    "all_skills = []\n",
    "\n",
    "for skills in df['extracted_skills']:\n",
    "    all_skills.extend(skills)\n",
    "\n",
    "# Count skill frequencies\n",
    "skill_counts = Counter(all_skills)\n",
    "\n",
    "# Display top 20 most common skills\n",
    "print(\"Top 20 most common skills:\")\n",
    "for skill, count in skill_counts.most_common(20):\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{skill}: {count} jobs ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed54c0",
   "metadata": {},
   "source": [
    "## Step 8: Save Extracted Skills\n",
    "\n",
    "Save the DataFrame with extracted skills to a CSV file.<br>\n",
    "The `to_csv()` function saves the DataFrame to `data/processed/`.<br>\n",
    "Use `index=False` to avoid saving the row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "89908bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: data/processed/job_title_des_with_skills.csv\n",
      "Total jobs: 2277\n",
      "Columns: ['Unnamed: 0', 'Job Title', 'Job Description', 'extracted_skills']\n"
     ]
    }
   ],
   "source": [
    "# Save with extracted skills\n",
    "df.to_csv('../data/processed/job_title_des_with_skills.csv', index=False)\n",
    "\n",
    "print(\"Data saved to: data/processed/job_title_des_with_skills.csv\")\n",
    "print(f\"Total jobs: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
